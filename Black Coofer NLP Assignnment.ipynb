{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1N8dhhYMTAQCh7OfwXPbktIg_ZoRYhA0h","authorship_tag":"ABX9TyOEfv2XnuxP+2D17f/lmC7e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"PocAtCfRUCMz","executionInfo":{"status":"ok","timestamp":1687158607807,"user_tz":-330,"elapsed":1568,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}}},"outputs":[],"source":["#importing library\n","import pandas as pd\n","import numpy as np\n","\n","import requests\n","from bs4 import BeautifulSoup\n","\n","import nltk\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk.corpus import stopwords\n","\n","import re\n","import os"]},{"cell_type":"code","source":["# Filter out all warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"ckCfhjndUN0i","executionInfo":{"status":"ok","timestamp":1687158607807,"user_tz":-330,"elapsed":3,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fh-xUUdvWftV","executionInfo":{"status":"ok","timestamp":1687158612202,"user_tz":-330,"elapsed":4398,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}},"outputId":"9417af84-30bb-45e5-aa47-6a25ed28369a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["#importing input file\n","df=pd.read_excel('/content/drive/MyDrive/Blackcoffer NLP Assignment/Input.xlsx')"],"metadata":{"id":"vpphvVOkW0Xq","executionInfo":{"status":"ok","timestamp":1687158612202,"user_tz":-330,"elapsed":12,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"3bYyeMYpXoiW","executionInfo":{"status":"ok","timestamp":1687158612202,"user_tz":-330,"elapsed":10,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}},"outputId":"c4ca5bfc-ea0e-49fb-ef28-deb22cdf7922"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   URL_ID                                                URL\n","0      37  https://insights.blackcoffer.com/ai-in-healthc...\n","1      38  https://insights.blackcoffer.com/what-if-the-c...\n","2      39  https://insights.blackcoffer.com/what-jobs-wil...\n","3      40  https://insights.blackcoffer.com/will-machine-...\n","4      41  https://insights.blackcoffer.com/will-ai-repla..."],"text/html":["\n","  <div id=\"df-5353a1f9-5e44-4807-b124-6be24391c70b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>URL_ID</th>\n","      <th>URL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37</td>\n","      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>38</td>\n","      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>39</td>\n","      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>40</td>\n","      <td>https://insights.blackcoffer.com/will-machine-...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>41</td>\n","      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5353a1f9-5e44-4807-b124-6be24391c70b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5353a1f9-5e44-4807-b124-6be24391c70b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5353a1f9-5e44-4807-b124-6be24391c70b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_2z5P4kxYpBo","executionInfo":{"status":"ok","timestamp":1687158612203,"user_tz":-330,"elapsed":9,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}},"outputId":"b2c9061d-b4e4-4fa2-c387-926a70ce6338"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(114, 2)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Function to extract article text from HTML content\n","def extract_article_text(html_content):\n","    soup = BeautifulSoup(html_content, 'html.parser')\n","    article_title = soup.find(class_='entry-title').text.strip()\n","\n","    # Check if the element with class 'td-post-content' exists\n","    article_text_element = soup.find(class_='td-post-content')\n","    if article_text_element is not None:\n","        article_text = article_text_element.text.strip()\n","    else:\n","        article_text = ''\n","\n","    return article_title, article_text\n","\n","folder_path = \"/content/drive/MyDrive/Blackcoffer NLP Assignment/Text Files Extracted/\"\n","\n","# Loop through the URLs and extract the article text\n","for index, row in df.iterrows():\n","    url_id = row['URL_ID']\n","    url = row['URL']\n","    #print(f\"Processing URL_ID {url_id}...\")\n","\n","    try:\n","        # Send a GET request to the URL\n","        response = requests.get(url)\n","        response.raise_for_status()  # Raise an exception if an HTTP error occurred\n","\n","        # Extract the article title and text from the response\n","        article_title, article_text = extract_article_text(response.content)\n","\n","        # Save the extracted article in a text file with URL_ID as the file name\n","        file_name = f\"{url_id}.txt\"\n","        file_path = os.path.join(folder_path, file_name)\n","        with open(file_path, 'w') as file:\n","            file.write(f\"Article Title: {article_title}\\n\")\n","            file.write(f\"Article Text: {article_text}\\n\")\n","\n","        #print(f\"Saved article with URL_ID {url_id} to {file_name}\")\n","\n","    except requests.exceptions.HTTPError as err:\n","        if response.status_code == 404:\n","            print(f\"{url_id} Ooops... Error 404 was found for that page\")\n","        else:\n","            print(f\"An HTTP error occurred: {err}\")\n","\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","\n","print(\"Data extraction completed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g7x9YKG2fnnl","executionInfo":{"status":"ok","timestamp":1687158668908,"user_tz":-330,"elapsed":56711,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}},"outputId":"d3e695ed-69ec-47c9-e8c9-163a623c51f7"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["44 Ooops... Error 404 was found for that page\n","57 Ooops... Error 404 was found for that page\n","144 Ooops... Error 404 was found for that page\n","Data extraction completed.\n"]}]},{"cell_type":"code","source":["directory = \"/content/drive/MyDrive/Blackcoffer NLP Assignment/Text Files Extracted/\"\n","\n","for filename in os.listdir(directory):\n","    filepath = os.path.join(directory, filename)\n","    if os.path.isfile(filepath):\n","        # Read the contents of the file\n","        with open(filepath, \"r\") as file:\n","            text = file.read()"],"metadata":{"id":"USYlQczrj8kJ","executionInfo":{"status":"ok","timestamp":1687158668909,"user_tz":-330,"elapsed":9,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["directory = \"/content/drive/MyDrive/Blackcoffer NLP Assignment/Text Files Extracted/\"\n","\n","data = []  # List to store the data\n","\n","# Iterate over each file in the directory\n","for filename in os.listdir(directory):\n","    filepath = os.path.join(directory, filename)\n","    if os.path.isfile(filepath):\n","        # Read the contents of the file\n","        with open(filepath, \"r\") as file:\n","            text = file.read()\n","            data.append({'Filename': filename, 'Text': text})\n","\n","# Create a DataFrame from the data list\n","df_extrated_data = pd.DataFrame(data)\n","\n","# Print the DataFrame\n","print(df_extrated_data.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FxGATFmnU7FI","executionInfo":{"status":"ok","timestamp":1687158668909,"user_tz":-330,"elapsed":8,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}},"outputId":"e650d60d-1990-4c3d-a3bb-4452820f99e2"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["  Filename                                               Text\n","0   37.txt  Article Title: Ranking customer behaviours for...\n","1   38.txt  Article Title: Ranking customer behaviours for...\n","2   39.txt  Article Title: Ranking customer behaviours for...\n","3   40.txt  Article Title: Ranking customer behaviours for...\n","4   41.txt  Article Title: Ranking customer behaviours for...\n"]}]},{"cell_type":"code","source":["nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LojaEEXBqm0F","executionInfo":{"status":"ok","timestamp":1687158668909,"user_tz":-330,"elapsed":6,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}},"outputId":"a6953447-0f7f-4721-91da-53a5747a34db"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Load stop words\n","stop_words_files = [\n","    \"/content/drive/MyDrive/Blackcoffer NLP Assignment/StopWords/StopWords_Auditor.txt\",\n","    \"/content/drive/MyDrive/Blackcoffer NLP Assignment/StopWords/StopWords_Currencies.txt\",\n","    \"/content/drive/MyDrive/Blackcoffer NLP Assignment/StopWords/StopWords_DatesandNumbers.txt\",\n","    \"/content/drive/MyDrive/Blackcoffer NLP Assignment/StopWords/StopWords_Generic.txt\",\n","    \"/content/drive/MyDrive/Blackcoffer NLP Assignment/StopWords/StopWords_GenericLong.txt\",\n","    \"/content/drive/MyDrive/Blackcoffer NLP Assignment/StopWords/StopWords_Geographic.txt\",\n","    \"/content/drive/MyDrive/Blackcoffer NLP Assignment/StopWords/StopWords_Names.txt\"\n","]\n","\n","stop_words = set()\n","for file in stop_words_files:\n","    with open(file, \"r\", encoding='latin-1') as f:\n","        words = f.read().split()\n","        stop_words.update(words)\n","\n","# Load positive and negative word lists\n","positive_words_file = \"/content/drive/MyDrive/Blackcoffer NLP Assignment/MasterDictionary/positive-words.txt\"\n","negative_words_file = \"/content/drive/MyDrive/Blackcoffer NLP Assignment/MasterDictionary/negative-words.txt\"\n","\n","positive_words = set()\n","negative_words = set()\n","\n","with open(positive_words_file, \"r\",encoding='latin-1') as f:\n","    positive_words = set(word for word in f.read().split() if word not in stop_words)\n","\n","with open(negative_words_file, \"r\", encoding='latin-1') as f:\n","    negative_words = set(word for word in f.read().split() if word not in stop_words)"],"metadata":{"id":"Zv6KjSWQu_h2","executionInfo":{"status":"ok","timestamp":1687158669728,"user_tz":-330,"elapsed":15,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def clean_text(text):\n","    # Tokenize the text into sentences\n","    sentences = sent_tokenize(text)\n","\n","    cleaned_words = []\n","    total_words = 0\n","\n","    for sentence in sentences:\n","        # Tokenize the sentence into words\n","        words = word_tokenize(sentence)\n","\n","        for word in words:\n","            # Remove punctuation and convert to lowercase\n","            cleaned_word = re.sub(r\"[^\\w\\s]\", \"\", word.lower())\n","\n","            # Remove stop words\n","            if cleaned_word not in stop_words and cleaned_word != \"\":\n","                cleaned_words.append(cleaned_word)\n","                total_words += 1\n","\n","    return cleaned_words, total_words"],"metadata":{"id":"HZXRdKgAXm3f","executionInfo":{"status":"ok","timestamp":1687158669728,"user_tz":-330,"elapsed":15,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def syllable_count(word):\n","    vowels = 'aeiouy'\n","    count = 0\n","    if len(word) == 0:\n","        return count\n","    if word[0] in vowels:\n","        count += 1\n","    for index in range(1, len(word)):\n","        if word[index] in vowels and word[index - 1] not in vowels:\n","            count += 1\n","    if word.endswith('e'):\n","        count -= 1\n","    if count == 0:\n","        count += 1\n","    return count"],"metadata":{"id":"zoyR3jCvXwCQ","executionInfo":{"status":"ok","timestamp":1687158669728,"user_tz":-330,"elapsed":15,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def sentimental_analysis(text, cleaned_words, positive_words, negative_words):\n","    positive_score = int(sum(1 for word in cleaned_words if word in positive_words))\n","    negative_score = int(sum(1 for word in cleaned_words if word in negative_words))\n","\n","    polarity_score = (positive_score - negative_score) / (positive_score + negative_score + 0.000001)\n","    subjectivity_score = (positive_score + negative_score) / (total_words + 0.000001)\n","\n","    return positive_score, negative_score, polarity_score, subjectivity_score"],"metadata":{"id":"BzhRokZLXv4r","executionInfo":{"status":"ok","timestamp":1687158669729,"user_tz":-330,"elapsed":15,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def analyze_readability(text):\n","    cleaned_words, total_words = clean_text(text)\n","    sentences = sent_tokenize(text)\n","    total_sentences = len(sentences)\n","    complex_word_count = sum(1 for word in cleaned_words if syllable_count(word) > 2)\n","\n","    average_sentence_length = total_words / total_sentences\n","    percentage_complex_words = complex_word_count / total_words\n","    fog_index = 0.4 * (average_sentence_length + percentage_complex_words)\n","\n","    return average_sentence_length, fog_index"],"metadata":{"id":"1E9immYPXlvp","executionInfo":{"status":"ok","timestamp":1687158669729,"user_tz":-330,"elapsed":14,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def calculate_average_words_per_sentence(text):\n","    sentences = sent_tokenize(text)\n","    total_sentences = len(sentences)\n","    total_words = len(word_tokenize(text))\n","    average_words_per_sentence = total_words / total_sentences\n","    return average_words_per_sentence"],"metadata":{"id":"j9qliv2sXloW","executionInfo":{"status":"ok","timestamp":1687158669729,"user_tz":-330,"elapsed":14,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def calculate_syllables_per_word(text):\n","    words = word_tokenize(text)\n","    total_syllables = sum(syllable_count(word) for word in words)\n","    total_words = len(words)\n","    syllables_per_word = total_syllables / total_words\n","    return syllables_per_word"],"metadata":{"id":"uqv7Gt1NXlh6","executionInfo":{"status":"ok","timestamp":1687158669729,"user_tz":-330,"elapsed":14,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def calculate_average_word_length(text):\n","    words = word_tokenize(text)\n","    total_words = len(words)\n","    total_characters = sum(len(word) for word in words)\n","    average_word_length = total_characters / total_words\n","    return average_word_length"],"metadata":{"id":"Qp-W0SxDXlc4","executionInfo":{"status":"ok","timestamp":1687158669729,"user_tz":-330,"elapsed":13,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def count_personal_pronouns(text):\n","    pronouns = [\"I\", \"me\", \"my\", \"mine\", \"we\", \"us\", \"our\", \"ours\", \"you\", \"your\", \"yours\", \"he\", \"him\", \"his\",\n","                \"she\", \"her\", \"hers\", \"it\", \"its\", \"they\", \"them\", \"their\", \"theirs\"]\n","    pronoun_count = 0\n","    words = word_tokenize(text)\n","    for word in words:\n","        if word.lower() in pronouns:\n","            pronoun_count += 1\n","    return pronoun_count"],"metadata":{"id":"2PhPAE-SXlQU","executionInfo":{"status":"ok","timestamp":1687158669730,"user_tz":-330,"elapsed":14,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Example Usage 1\n","text1 = \"This is a positive sentence.\"\n","cleaned_words, total_words = clean_text(text1)\n","positive_score, negative_score, polarity_score, subjectivity_score = sentimental_analysis(text1, cleaned_words, positive_words, negative_words)\n","print(\"Positive Score:\", positive_score)\n","print(\"Negative Score:\", negative_score)\n","print(\"Polarity Score:\", polarity_score)\n","print(\"Subjectivity Score:\", subjectivity_score)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8oBuvy7fpqhH","executionInfo":{"status":"ok","timestamp":1687158669730,"user_tz":-330,"elapsed":14,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}},"outputId":"ff1e548d-90f7-40d6-ccf3-c6897a9dd830"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Positive Score: 1\n","Negative Score: 0\n","Polarity Score: 0.9999990000010001\n","Subjectivity Score: 0.499999750000125\n"]}]},{"cell_type":"code","source":["# Example Usage 2\n","text2 = \"This is a sample text for readability analysis.\"\n","average_sentence_length, fog_index = analyze_readability(text2)\n","print(\"Average Sentence Length:\", average_sentence_length)\n","print(\"FOG Index:\", fog_index)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"06Qv0SU4qjdc","executionInfo":{"status":"ok","timestamp":1687158669730,"user_tz":-330,"elapsed":11,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}},"outputId":"c6dffb9a-aaec-468e-b8b0-75ec4338e56a"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Average Sentence Length: 4.0\n","FOG Index: 1.8\n"]}]},{"cell_type":"code","source":["# Example Usage 3\n","text3 = \"I love to travel and explore new places. You should join us on our next adventure!\"\n","avg_word_length = calculate_average_word_length(text3)\n","pronoun_count = count_personal_pronouns(text3)\n","\n","print(\"Average word length:\", avg_word_length)\n","print(\"Personal pronoun count:\", pronoun_count)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fNkmWFjCu-re","executionInfo":{"status":"ok","timestamp":1687158669730,"user_tz":-330,"elapsed":9,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}},"outputId":"a543026f-8539-4807-aa35-407690dcf855"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Average word length: 3.7222222222222223\n","Personal pronoun count: 3\n"]}]},{"cell_type":"code","source":["# Example Usage 4\n","sample_text = \"This is a sample text. It contains both positive and negative words. This text will be used to demonstrate the calculation of variables.\"\n","\n","# Perform calculations for the sample text\n","cleaned_words, total_words = clean_text(sample_text)\n","positive_score, negative_score, polarity_score, subjectivity_score = sentimental_analysis(sample_text, cleaned_words, positive_words, negative_words)\n","average_sentence_length, fog_index = analyze_readability(sample_text)\n","average_words_per_sentence = calculate_average_words_per_sentence(sample_text)\n","complex_word_count = sum(1 for word in cleaned_words if syllable_count(word) > 2)\n","syllables_per_word = calculate_syllables_per_word(sample_text)\n","personal_pronouns = count_personal_pronouns(sample_text)\n","average_word_length = calculate_average_word_length(sample_text)\n","\n","# Print the calculated values\n","print(\"Cleaned Text:\", cleaned_words)\n","print(\"Total Words:\", total_words)\n","print(\"Positive Score:\", positive_score)\n","print(\"Negative Score:\", negative_score)\n","print(\"Polarity Score:\", polarity_score)\n","print(\"Subjectivity Score:\", subjectivity_score)\n","print(\"Average Sentence Length:\", average_sentence_length)\n","print(\"Fog Index:\", fog_index)\n","print(\"Average Words per Sentence:\", average_words_per_sentence)\n","print(\"Complex Word Count:\", complex_word_count)\n","print(\"Syllables per Word:\", syllables_per_word)\n","print(\"Personal Pronouns:\", personal_pronouns)\n","print(\"Average Word Length:\", average_word_length)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sSOZOI1W3Zc2","executionInfo":{"status":"ok","timestamp":1687158669731,"user_tz":-330,"elapsed":8,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}},"outputId":"45fabfc0-2428-48fe-8793-76faaf441a39"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Cleaned Text: ['sample', 'text', 'positive', 'negative', 'words', 'text', 'demonstrate', 'calculation', 'variables']\n","Total Words: 9\n","Positive Score: 1\n","Negative Score: 1\n","Polarity Score: 0.0\n","Subjectivity Score: 0.22222219753086697\n","Average Sentence Length: 3.0\n","Fog Index: 1.4222222222222223\n","Average Words per Sentence: 8.666666666666666\n","Complex Word Count: 5\n","Syllables per Word: 1.5\n","Personal Pronouns: 1\n","Average Word Length: 4.384615384615385\n"]}]},{"cell_type":"code","source":["# Convert positive_words set to a DataFrame\n","positive_words_df = pd.DataFrame(positive_words, columns=['Positive Words'])\n","\n","# Save the DataFrame to a CSV file\n","positive_words_df.to_csv('/content/drive/MyDrive/Blackcoffer NLP Assignment/positive_words.csv', index=False)"],"metadata":{"id":"S-0JtAQ__bPf","executionInfo":{"status":"ok","timestamp":1687158669731,"user_tz":-330,"elapsed":6,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Convert positive_words set to a DataFrame\n","negative_words_df = pd.DataFrame(negative_words, columns=['Negative Words'])\n","\n","# Save the DataFrame to a CSV file\n","negative_words_df.to_csv('/content/drive/MyDrive/Blackcoffer NLP Assignment/negative_words.csv', index=False)"],"metadata":{"id":"__6zhonQWqYz","executionInfo":{"status":"ok","timestamp":1687158669731,"user_tz":-330,"elapsed":6,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Read the output file\n","output_file = '/content/drive/MyDrive/Blackcoffer NLP Assignment/Output Data Structure.xlsx'\n","df_output = pd.read_excel(output_file)\n","\n","# Iterate over the URLs and calculate the variables for each URL\n","for index, row in df_output.iterrows():\n","    url_id = row['URL_ID']\n","    file_name = f\"{url_id}.txt\"\n","    folder_path=\"/content/drive/MyDrive/Blackcoffer NLP Assignment/Text Files Extracted/\"\n","    file_path = os.path.join(folder_path, file_name)  # Include the folder path\n","\n","    # Check if the file exists\n","    if os.path.isfile(file_path):  # Use the file_path variable\n","        # Read the contents of the file\n","        with open(file_path, \"r\") as file:  # Use the file_path variable\n","            text = file.read()\n","\n","        # Perform calculations for each URL\n","        cleaned_words, total_words = clean_text(text)\n","        positive_score, negative_score, polarity_score, subjectivity_score = sentimental_analysis(text,cleaned_words, positive_words, negative_words)\n","        average_sentence_length, fog_index = analyze_readability(text)\n","        average_words_per_sentence = calculate_average_words_per_sentence(text)\n","        complex_word_count = sum(1 for word in cleaned_words if syllable_count(word) > 2)\n","        syllables_per_word = calculate_syllables_per_word(text)\n","        personal_pronouns = count_personal_pronouns(text)\n","        average_word_length = calculate_average_word_length(text)\n","\n","        # Append the calculated values to the output dataframe\n","        df_output.at[index, 'POSITIVE SCORE'] = positive_score\n","        df_output.at[index, 'NEGATIVE SCORE'] = negative_score\n","        df_output.at[index, 'POLARITY SCORE'] = polarity_score\n","        df_output.at[index, 'SUBJECTIVITY SCORE'] = subjectivity_score\n","        df_output.at[index, 'AVG SENTENCE LENGTH'] = average_sentence_length\n","        df_output.at[index, 'PERCENTAGE OF COMPLEX WORDS'] = complex_word_count / total_words\n","        df_output.at[index, 'FOG INDEX'] = fog_index\n","        df_output.at[index, 'AVG NUMBER OF WORDS PER SENTENCE'] = average_words_per_sentence\n","        df_output.at[index, 'COMPLEX WORD COUNT'] = complex_word_count\n","        df_output.at[index, 'WORD COUNT'] = total_words\n","        df_output.at[index, 'SYLLABLE PER WORD'] = syllables_per_word\n","        df_output.at[index, 'PERSONAL PRONOUNS'] = personal_pronouns\n","        df_output.at[index, 'AVG WORD LENGTH'] = average_word_length\n","\n","    else:\n","        # Fill empty variables with \"NA\"\n","        df_output.at[index, 'POSITIVE SCORE'] = \"NA\"\n","        df_output.at[index, 'NEGATIVE SCORE'] = \"NA\"\n","        df_output.at[index, 'POLARITY SCORE'] = \"NA\"\n","        df_output.at[index, 'SUBJECTIVITY SCORE'] = \"NA\"\n","        df_output.at[index, 'AVG SENTENCE LENGTH'] = \"NA\"\n","        df_output.at[index, 'PERCENTAGE OF COMPLEX WORDS'] = \"NA\"\n","        df_output.at[index, 'FOG INDEX'] = \"NA\"\n","        df_output.at[index, 'AVG NUMBER OF WORDS PER SENTENCE'] = \"NA\"\n","        df_output.at[index, 'COMPLEX WORD COUNT'] = \"NA\"\n","        df_output.at[index, 'WORD COUNT'] = \"NA\"\n","        df_output.at[index, 'SYLLABLE PER WORD'] = \"NA\"\n","        df_output.at[index, 'PERSONAL PRONOUNS'] = \"NA\"\n","        df_output.at[index, 'AVG WORD LENGTH'] = \"NA\"\n","\n","# Save the updated output dataframe to the file\n","df_output.to_excel(output_file, index=False)"],"metadata":{"id":"o47loOULXQ72","executionInfo":{"status":"ok","timestamp":1687158679231,"user_tz":-330,"elapsed":9506,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1ycR_G7hcbUn","executionInfo":{"status":"ok","timestamp":1687158679234,"user_tz":-330,"elapsed":53,"user":{"displayName":"KESHAV MUNDRA","userId":"10687801356851299899"}}},"execution_count":26,"outputs":[]}]}